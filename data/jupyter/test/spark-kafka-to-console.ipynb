{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d090b02-8222-4fdc-8773-2d6cc4e383ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYSPARK_PYTHON\"]=\"/usr/bin/python3\"\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.4.3,org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.3 pyspark-shell'\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark import  SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "from pyspark.sql import SQLContext\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c62a8-0e4e-4f58-9f84-4b56fb630fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_conf = SparkConf() \\\n",
    "            .setMaster(\"spark://spark-master:7077\") \\\n",
    "            .setAppName(\"SparkKafkaStreamingConsole\") \\\n",
    "            .setAll([('spark.executor.memory', '4g'),\n",
    "                     ('spark.executor.cores', '4'), \n",
    "                     ('spark.cores.max', '4'), \n",
    "                     ('spark.driver.memory','4g'),\n",
    "                     ('spark.driver.host','192.168.96.3')\n",
    "            ])\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .config(conf=spark_conf) \\\n",
    "                    .enableHiveSupport() \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee33e081-4992-4a29-a85e-187ac25f1568",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = spark \\\n",
    "        .readStream \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", \"kafka:9092\") \\\n",
    "        .option(\"subscribe\", \"topic1\") \\\n",
    "        .option(\"startingOffsets\", \"latest\") \\\n",
    "        .load() \\\n",
    "        .selectExpr(\"CAST(value as STRING)\", \"CAST(timestamp as STRING)\",\"CAST(topic as STRING)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb2c51d-bd0a-4d6a-b24f-a4b857b926c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = input_df.writeStream \\\n",
    "            .format(\"console\") \\\n",
    "            .option(\"truncate\",\"false\") \\\n",
    "            .start() \\\n",
    "            .awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc6dff5-8235-4774-a55e-70ebe8ae32d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveToHBase(rdd):\n",
    "#     print(\"=====Pull from Stream=====\")\n",
    "    if not rdd.isEmpty():\n",
    "        host = 'localhost:2182'\n",
    "        table = 'logs'  \n",
    "        keyConv = \"org.apache.spark.examples.pythonconverters.StringToImmutableBytesWritableConverter\"  \n",
    "        valueConv = \"org.apache.spark.examples.pythonconverters.StringListToPutConverter\"  \n",
    "        conf = {\"hbase.zookeeper.quorum\": host,\n",
    "                \"hbase.zookeeper.property.clientPort\": \"2182\",\n",
    "            \"hbase.mapred.outputtable\": table,\n",
    "            \"mapreduce.outputformat.class\": \"org.apache.hadoop.hbase.mapreduce.TableOutputFormat\",  \n",
    "            \"mapreduce.job.output.key.class\": \"org.apache.hadoop.hbase.io.ImmutableBytesWritable\",  \n",
    "            \"mapreduce.job.output.value.class\": \"org.apache.hadoop.io.Writable\"}\n",
    "        rdd.saveAsNewAPIHadoopDataset(conf=conf,keyConverter=keyConv,valueConverter=valueConv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
